{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "20a06fc4",
      "metadata": {},
      "source": [
        "# Coffee Leaf Diseases Prediction\n",
        "\n",
        "## Overview\n",
        "This notebook is a reproduction of the coffee leaf disease classification method described in the research paper below, using machine learning techniques with RGB and CMY color features.\n",
        "\n",
        "## References\n",
        "\n",
        "### Research Paper\n",
        "- **Title**: Comparative Analysis of the Performance of the Decision Tree and K-Nearest Neighbors Methods in Classifying Coffee Leaf Diseases\n",
        "- **Authors**: Adie Suryadi, Murhaban Murhaban, Rivansyah Suhendra\n",
        "- **Published in**: Department of Information Technology, Teuku Umar University, Indonesia\n",
        "- **URL**: [https://aptikom-journal.id/conferenceseries/article/view/649/272](https://aptikom-journal.id/conferenceseries/article/view/649/272)\n",
        "\n",
        "### Dataset\n",
        "- **Dataset**: Coffee Leaf Diseases\n",
        "- **Source**: Kaggle\n",
        "- **URL**: [https://www.kaggle.com/datasets/badasstechie/coffee-leaf-diseases/code](https://www.kaggle.com/datasets/badasstechie/coffee-leaf-diseases/code)\n",
        "\n",
        "## Methodology\n",
        "This implementation extracts color-based features from coffee leaf images:\n",
        "- **RGB features**: Mean and standard deviation for each R, G, B channel (6 features)\n",
        "- **CMY features**: Mean and standard deviation for each C, M, Y channel (6 features)\n",
        "- **Total**: 12 color-based features per image\n",
        "\n",
        "The features are then used to classify coffee leaves into four categories:\n",
        "- Miner\n",
        "- Phoma\n",
        "- Rust\n",
        "- No disease"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e84172d",
      "metadata": {},
      "source": [
        "## Preprocessing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17bab194",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def load_and_extract_features(image_dir, labels_df):\n",
        "    features_list = []\n",
        "    valid_indices = []\n",
        "    \n",
        "    for idx, row in labels_df.iterrows():\n",
        "        img_path = os.path.join(image_dir, f\"{row['id']}.jpg\")\n",
        "        \n",
        "        if os.path.exists(img_path):\n",
        "            img = Image.open(img_path)\n",
        "            img_resized = img.resize((100, 50), Image.Resampling.BILINEAR) # resize to 100x50\n",
        "            img_array = np.array(img_resized).astype('float32') / 255.0 # normalize \n",
        "            \n",
        "            features_list.append(img_array)\n",
        "            valid_indices.append(idx)\n",
        "        else:\n",
        "            print(f\"Warning: {img_path} not found\")\n",
        "    \n",
        "    features_array = np.array(features_list)\n",
        "    labels = labels_df.loc[valid_indices].reset_index(drop=True)\n",
        "    labels = labels.drop(columns=['id'], axis=1)\n",
        "    \n",
        "    return features_array, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe4bc695",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "train_label_df = pd.read_csv('dataset/train_classes.csv')\n",
        "test_label_df = pd.read_csv('dataset/test_classes.csv')\n",
        "\n",
        "train_features, train_labels = load_and_extract_features('dataset/coffee-leaf-diseases/train/images', train_label_df)\n",
        "test_features, test_labels = load_and_extract_features('dataset/coffee-leaf-diseases/test/images', test_label_df)\n",
        "\n",
        "train_features_flat = train_features.reshape(train_features.shape[0], -1)\n",
        "test_features_flat = test_features.reshape(test_features.shape[0], -1)\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    train_features_flat, \n",
        "    train_labels,\n",
        "    test_size=0.2,\n",
        "    stratify=train_labels,\n",
        "    random_state=123\n",
        ")\n",
        "print(f\"\\nShape of X_train: {X_train.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91a720c8",
      "metadata": {},
      "outputs": [],
      "source": [
        "label_counts = np.sum(train_labels.values, axis=0)\n",
        "print(\"Label distribution in training set:\")\n",
        "for label, count in zip(train_labels.columns, label_counts):\n",
        "    print(f\"{label}: {count} samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19f31338",
      "metadata": {},
      "source": [
        "## Bulid and Evaluate Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22ce4729",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import Pipeline as SKPipeline\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "def build_model(model_type, model, param_grid):\n",
        "    pipeline = SKPipeline([\n",
        "        ('pca', PCA(random_state=123)),\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('multi_output', MultiOutputClassifier(model, n_jobs=-1))\n",
        "    ])\n",
        "    \n",
        "    grid = GridSearchCV(\n",
        "        estimator=pipeline,\n",
        "        param_grid=param_grid,\n",
        "        scoring='f1_macro',\n",
        "        cv=10,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    \n",
        "    grid.fit(X_train, y_train)\n",
        "    print(f\"Best parameters for {model_type}: {grid.best_params_}\")\n",
        "    print(f\"Best F1 Macro Score for {model_type}: {grid.best_score_}\")\n",
        "    \n",
        "    return grid.best_estimator_\n",
        "\n",
        "# ---------- Decision Tree ----------\n",
        "best_multilable_dt = build_model(\n",
        "    'Decision Tree',\n",
        "    DecisionTreeClassifier(),\n",
        "    {\n",
        "        'pca__n_components': [10, 20, 50],\n",
        "        'multi_output__estimator__criterion': ['gini', 'entropy'],\n",
        "        'multi_output__estimator__max_depth': [5, 8, 13, 18, None],\n",
        "        'multi_output__estimator__min_samples_split': [2, 5],\n",
        "        'multi_output__estimator__min_samples_leaf': [1, 3],\n",
        "        'multi_output__estimator__class_weight': ['balanced', None],\n",
        "        'multi_output__estimator__min_impurity_decrease': [0.0, 0.001, 0.01]\n",
        "    }\n",
        ")\n",
        "\n",
        "# ---------- KNN ----------\n",
        "best_multilable_knn = build_model(\n",
        "    'KNN',\n",
        "    KNeighborsClassifier(),\n",
        "    {\n",
        "        'pca__n_components': [10, 20, 50],\n",
        "        'multi_output__estimator__n_neighbors': [1, 3, 5, 7, 9],\n",
        "        'multi_output__estimator__metric': ['euclidean', 'manhattan', 'cosine'],\n",
        "        'multi_output__estimator__weights': ['uniform', 'distance']\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1f8f467",
      "metadata": {},
      "source": [
        "#### Evaluation on Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69d596ed",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "def show_evaluation_results(model_type, pred, actual):\n",
        "    print(f\"\\n=== {model_type} Overall Metrics ===\")\n",
        "    print(\"Accuracy (subset accuracy):\", accuracy_score(actual, pred))\n",
        "    print(\"Precision (micro):\", precision_score(actual, pred, average='micro', zero_division=0))\n",
        "    print(\"Recall (micro):\", recall_score(actual, pred, average='micro', zero_division=0))\n",
        "    print(\"F1-score (micro):\", f1_score(actual, pred, average='micro', zero_division=0))\n",
        "    print(\"Precision (macro):\", precision_score(actual, pred, average='macro', zero_division=0))\n",
        "    print(\"Recall (macro):\", recall_score(actual, pred, average='macro', zero_division=0))\n",
        "    print(\"F1-score (macro):\", f1_score(actual, pred, average='macro', zero_division=0))\n",
        "\n",
        "# ---------- Decision Tree ----------\n",
        "y_pred_valid_multilabel_dt = best_multilable_dt.predict(X_valid)\n",
        "\n",
        "show_evaluation_results(\n",
        "    \"Decision Tree\",\n",
        "    y_pred_valid_multilabel_dt,\n",
        "    y_valid\n",
        ")\n",
        "\n",
        "# ---------- KNN ----------\n",
        "y_pred_valid_multilabel_knn = best_multilable_knn.predict(X_valid)\n",
        "\n",
        "show_evaluation_results(\n",
        "    \"KNN\",\n",
        "    y_pred_valid_multilabel_knn,\n",
        "    y_valid\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5001b12a",
      "metadata": {},
      "source": [
        "##### Confusion Matrix Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bef28d04",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "labels = y_valid.columns\n",
        "\n",
        "def plot_confusion_matrix(model_type, pred, actual):\n",
        "    \n",
        "    pred_array = np.array(pred)\n",
        "    actual_array = np.array(actual)\n",
        "    \n",
        "    plt.figure(figsize=(15, 4))\n",
        "    \n",
        "    for i, label_name in enumerate(labels):\n",
        "        y_true_label = actual_array[:, i]\n",
        "        y_pred_label = pred_array[:, i]\n",
        "        \n",
        "        cm = confusion_matrix(y_true_label, y_pred_label)\n",
        "        \n",
        "        plt.subplot(1, len(labels), i + 1)\n",
        "        sns.heatmap(\n",
        "            cm,\n",
        "            annot=True,\n",
        "            fmt='d',\n",
        "            cmap='Greens',\n",
        "            xticklabels=['Not ' + label_name, label_name],\n",
        "            yticklabels=['Not ' + label_name, label_name]\n",
        "        )\n",
        "        plt.title(f'{model_type} Confusion Matrix - {label_name}')\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('Actual')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ---------- Decision Tree ----------\n",
        "plot_confusion_matrix(\n",
        "    'Decision Tree',\n",
        "    y_pred_valid_multilabel_dt,\n",
        "    y_valid\n",
        ")\n",
        "\n",
        "# ---------- KNN ----------\n",
        "plot_confusion_matrix(\n",
        "    'KNN',\n",
        "    y_pred_valid_multilabel_knn,\n",
        "    y_valid\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2e96bea",
      "metadata": {},
      "source": [
        "##### ROC-AUC Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f4d4ed9",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "def plot_roc_curve(model_type, model, pred_target, actual):\n",
        "    actual_array = np.array(actual)\n",
        "    y_score = model.predict_proba(pred_target)\n",
        "    \n",
        "    is_multioutput_style = False\n",
        "    if isinstance(model, SKPipeline) and isinstance(model.steps[-1][1], MultiOutputClassifier):\n",
        "        is_multioutput_style = True\n",
        "    elif isinstance(model, MultiOutputClassifier):\n",
        "        is_multioutput_style = True\n",
        "\n",
        "    # convert to np.array\n",
        "    if is_multioutput_style:\n",
        "        y_score_array = np.column_stack([proba[:, 1] for proba in y_score])\n",
        "    else:\n",
        "        y_score_array = np.array(y_score)\n",
        "        \n",
        "    plt.figure(figsize=(8, 6))\n",
        "    for i, class_name in enumerate(labels):\n",
        "        fpr_dt, tpr_dt, _ = roc_curve(actual_array[:, i], y_score_array[:, i])\n",
        "        roc_auc_dt_best = auc(fpr_dt, tpr_dt)\n",
        "        plt.plot(\n",
        "            fpr_dt,\n",
        "            tpr_dt,\n",
        "            lw=2,\n",
        "            label=f'{class_name} (AUC = {roc_auc_dt_best:.4f})'\n",
        "        )\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'{model_type} ROC Curve for Predicting Test Set Using the Best Model - Decision Tree')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# ---------- Decision Tree ----------\n",
        "plot_roc_curve(\n",
        "    'Decision Tree',\n",
        "    best_multilable_dt,\n",
        "    X_valid,\n",
        "    y_valid\n",
        ")\n",
        "\n",
        "# ---------- KNN ----------\n",
        "plot_roc_curve(\n",
        "    'KNN',\n",
        "    best_multilable_knn,\n",
        "    X_valid,\n",
        "    y_valid\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "143157d5",
      "metadata": {},
      "source": [
        "#### Evaluation on Test Set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5abe6ec",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---------- Decision Tree ----------\n",
        "y_pred_test_multilabel_dt = best_multilable_dt.predict(test_features_flat)\n",
        "\n",
        "show_evaluation_results(\n",
        "    \"Decision Tree\",\n",
        "    y_pred_test_multilabel_dt,\n",
        "    test_labels\n",
        ")\n",
        "\n",
        "# ---------- KNN ----------\n",
        "y_pred_test_multilabel_knn = best_multilable_knn.predict(test_features_flat)\n",
        "\n",
        "show_evaluation_results(\n",
        "    \"KNN\",\n",
        "    y_pred_test_multilabel_knn,\n",
        "    test_labels\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c64fdcc",
      "metadata": {},
      "source": [
        "##### Confusion Matrix Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d3a9ffb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---------- Decision Tree ----------\n",
        "plot_confusion_matrix(\n",
        "    'Decision Tree',\n",
        "    y_pred_test_multilabel_dt,\n",
        "    test_labels\n",
        ")\n",
        "\n",
        "# ---------- KNN ----------\n",
        "plot_confusion_matrix(\n",
        "    'KNN',\n",
        "    y_pred_test_multilabel_knn,\n",
        "    test_labels\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e7de238",
      "metadata": {},
      "source": [
        "##### ROC-AUC Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b83219c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---------- Decision Tree ----------\n",
        "plot_roc_curve(\n",
        "    'Decision Tree',\n",
        "    best_multilable_dt,\n",
        "    test_features_flat,\n",
        "    test_labels\n",
        ")\n",
        "\n",
        "# ---------- KNN ----------\n",
        "plot_roc_curve(\n",
        "    'KNN',\n",
        "    best_multilable_knn,\n",
        "    test_features_flat,\n",
        "    test_labels\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6fbcde9",
      "metadata": {},
      "source": [
        "### Apply SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dffcfce",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.base import clone\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold # CV with SMOTE\n",
        "\n",
        "# Combine best estimators (custom multi-output)\n",
        "class CustomMultiOutputEstimator:\n",
        "    def __init__(self, estimators):\n",
        "        self.estimators = estimators\n",
        "        \n",
        "    def predict(self, X):\n",
        "        # Generate predictions for each estimator and stack them\n",
        "        predictions = [est.predict(X).reshape(-1, 1) for est in self.estimators]\n",
        "        return np.hstack(predictions)\n",
        "    \n",
        "    def predict_proba(self, X):\n",
        "        # Generate probability predictions for each estimator\n",
        "        proba_list = []\n",
        "        for est in self.estimators:\n",
        "            proba = est.predict_proba(X)[:, 1].reshape(-1, 1)\n",
        "            proba_list.append(proba)\n",
        "            \n",
        "        return np.hstack(proba_list)\n",
        "\n",
        "\n",
        "def build_model_smote(model_type, model, param_grid):\n",
        "    \n",
        "    # A list to store best estimators from each fold\n",
        "    best_estimators_list = []\n",
        "    \n",
        "    # A list to store best macro scores from each fold\n",
        "    best_macro_scores = []\n",
        "    \n",
        "    y_train_np = np.array(y_train)\n",
        "    X_train_np = np.array(X_train)\n",
        "    \n",
        "    # Loop through each label for multi-label classification\n",
        "    for i in range(y_train.shape[1]):\n",
        "        print(f\"Processing label {i+1}/{y_train.shape[1]}\")\n",
        "        \n",
        "        y_label = y_train_np[:, i]\n",
        "        \n",
        "        if len(np.unique(y_label)) < 2:\n",
        "            print(f\"Skipping label {i+1} since it has only one class.\")\n",
        "            continue\n",
        "        \n",
        "        # Define pipeline for single label\n",
        "        single_label_pipeline = ImbPipeline([\n",
        "            ('pca', PCA(random_state=123)),\n",
        "            ('scaler', StandardScaler()),\n",
        "            ('smote', SMOTE(random_state=123)),\n",
        "            ('model', clone(model))\n",
        "        ])\n",
        "        \n",
        "        # Use StratifiedKFold for better representation of classes in each fold\n",
        "        cv_splitter = StratifiedKFold(n_splits=10, shuffle=True, random_state=123)\n",
        "        \n",
        "        grid = RandomizedSearchCV(\n",
        "            estimator=single_label_pipeline,\n",
        "            param_distributions=param_grid,\n",
        "            n_iter=200,\n",
        "            scoring='f1',\n",
        "            cv=cv_splitter,\n",
        "            n_jobs=-1,\n",
        "            random_state=123\n",
        "        )\n",
        "        \n",
        "        grid.fit(X_train_np, y_label)\n",
        "        \n",
        "        print(f\"Best parameters for {model_type} label {i+1}: {grid.best_params_}\")\n",
        "        print(f\"Best F1 score for label {i+1}: {grid.best_score_}\")\n",
        "        best_estimators_list.append(grid.best_estimator_)\n",
        "        best_macro_scores.append(grid.best_score_)\n",
        "    \n",
        "    return CustomMultiOutputEstimator(best_estimators_list)\n",
        "\n",
        "# ---------- Decision Tree ----------\n",
        "best_multilable_dt_smote = build_model_smote(\n",
        "    'Decision Tree',\n",
        "    DecisionTreeClassifier(),\n",
        "    {\n",
        "        'pca__n_components': [10, 20, 50],\n",
        "        'smote__k_neighbors': [3, 5, 7, 11],\n",
        "        'model__criterion': ['gini', 'entropy'],\n",
        "        'model__max_depth': [5, 8, 13, 18, None],\n",
        "        'model__min_samples_split': [2, 5],\n",
        "        'model__min_samples_leaf': [1, 3],\n",
        "        'model__class_weight': ['balanced', None],\n",
        "        'model__min_impurity_decrease': [0.0, 0.001, 0.01]\n",
        "    }\n",
        ")\n",
        "\n",
        "# ---------- KNN ----------\n",
        "best_multilable_knn_smote = build_model_smote(\n",
        "    'KNN',\n",
        "    KNeighborsClassifier(),\n",
        "    {\n",
        "        'pca__n_components': [10, 20, 50],\n",
        "        'smote__k_neighbors': [3, 5, 7, 11],\n",
        "        'model__n_neighbors': [1, 3, 5, 7, 9],\n",
        "        'model__metric': ['euclidean', 'manhattan', 'cosine'],\n",
        "        'model__weights': ['uniform', 'distance']\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f4456eb",
      "metadata": {},
      "source": [
        "#### Evaluation on Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38f52c58",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---------- Decision Tree ----------\n",
        "y_pred_valid_multilabel_dt_smote = best_multilable_dt_smote.predict(X_valid)\n",
        "\n",
        "show_evaluation_results(\n",
        "    \"Decision Tree\",\n",
        "    y_pred_valid_multilabel_dt_smote,\n",
        "    y_valid\n",
        ")\n",
        "\n",
        "# ---------- KNN ----------\n",
        "y_pred_valid_multilabel_knn_smote = best_multilable_knn_smote.predict(X_valid)\n",
        "\n",
        "show_evaluation_results(\n",
        "    \"KNN\",\n",
        "    y_pred_valid_multilabel_knn_smote,\n",
        "    y_valid\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a92e08b8",
      "metadata": {},
      "source": [
        "##### Confusion Matrix Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d0e3f77",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---------- Decision Tree ----------\n",
        "plot_confusion_matrix(\n",
        "    'Decision Tree',\n",
        "    y_pred_valid_multilabel_dt_smote,\n",
        "    y_valid\n",
        ")\n",
        "\n",
        "# ---------- KNN ----------\n",
        "plot_confusion_matrix(\n",
        "    'KNN',\n",
        "    y_pred_valid_multilabel_knn_smote,\n",
        "    y_valid\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "818e165e",
      "metadata": {},
      "source": [
        "##### ROC-AUC Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cd28c90",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---------- Decision Tree ----------\n",
        "plot_roc_curve(\n",
        "    'Decision Tree',\n",
        "    best_multilable_dt_smote,\n",
        "    X_valid,\n",
        "    y_valid\n",
        ")\n",
        "\n",
        "# ---------- KNN ----------\n",
        "plot_roc_curve(\n",
        "    'KNN',\n",
        "    best_multilable_knn_smote,\n",
        "    X_valid,\n",
        "    y_valid\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99203b76",
      "metadata": {},
      "source": [
        "#### Evaluation on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "027f0473",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---------- Decision Tree ----------\n",
        "y_pred_test_multilabel_dt_smote = best_multilable_dt_smote.predict(test_features_flat)\n",
        "\n",
        "show_evaluation_results(\n",
        "    \"Decision Tree\",\n",
        "    y_pred_test_multilabel_dt_smote,\n",
        "    test_labels\n",
        ")\n",
        "\n",
        "# ---------- KNN ----------\n",
        "y_pred_test_multilabel_knn_smote = best_multilable_knn_smote.predict(test_features_flat)\n",
        "\n",
        "show_evaluation_results(\n",
        "    \"KNN\",\n",
        "    y_pred_test_multilabel_knn_smote,\n",
        "    test_labels\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da570cd0",
      "metadata": {},
      "source": [
        "##### Confusion Matrix Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f31d4264",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---------- Decision Tree ----------\n",
        "plot_confusion_matrix(\n",
        "    'Decision Tree',\n",
        "    y_pred_test_multilabel_dt_smote,\n",
        "    test_labels\n",
        ")\n",
        "\n",
        "# ---------- KNN ----------\n",
        "plot_confusion_matrix(\n",
        "    'KNN',\n",
        "    y_pred_test_multilabel_knn_smote,\n",
        "    test_labels\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f27607d5",
      "metadata": {},
      "source": [
        "##### ROC-AUC Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bf96747",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---------- Decision Tree ----------\n",
        "plot_roc_curve(\n",
        "    'Decision Tree',\n",
        "    best_multilable_dt_smote,\n",
        "    test_features_flat,\n",
        "    test_labels\n",
        ")\n",
        "\n",
        "# ---------- KNN ----------\n",
        "plot_roc_curve(\n",
        "    'KNN',\n",
        "    best_multilable_knn_smote,\n",
        "    test_features_flat,\n",
        "    test_labels\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22a25ab6",
      "metadata": {},
      "source": [
        "## Combine All Train and Test Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "807fec4d",
      "metadata": {},
      "outputs": [],
      "source": [
        "all_features = np.vstack([train_features, test_features])\n",
        "all_labels = pd.concat([train_labels, test_labels], axis=0)\n",
        "\n",
        "all_features_flat = all_features.reshape(all_features.shape[0], -1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    all_features_flat,\n",
        "    all_labels,\n",
        "    test_size=0.2,\n",
        "    stratify=all_labels,\n",
        "    random_state=123\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81970255",
      "metadata": {},
      "source": [
        "## Save models\n",
        "\n",
        "To save scikit-learn models, we use `joblib` which is more efficient for large numpy arrays:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0075602",
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(best_multilable_knn_smote, 'best_multilabel_knn_smote.pkl')\n",
        "joblib.dump(best_multilable_dt_smote, 'best_multilabel_dt_smote.pkl')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
