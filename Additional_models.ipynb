{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Adding different classification models except in the research paper to the experimentation process.\n",
    "\n",
    "✅ Models\n",
    "- Logistic Regression\n",
    "- Neural Network\n",
    "\n",
    "✅ Code Workflow\n",
    "1. Model training and evaluation using train_classes.csv - Validation Set\n",
    "   - Split the training data further into train and validation data\n",
    "   - Perform hyperparameter tuning with GridSearchCV or similar methods\n",
    "   - Assess performance on the validation set\n",
    "\n",
    "2. Final evaluation using test_classes.csv - Test Set\n",
    "   - Use the optimal model trained on train + validation data\n",
    "   - Generate predictions on the test set\n",
    "\n",
    "3. Re-training and evaluation using the combined train_classes.csv and test_classes.csv - Combined Set (Validation Set + Test Set)\n",
    "   - Rebuild the model using the entire dataset\n",
    "   - Obtain the final model trained on all available data\n"
   ],
   "id": "20a06fc4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing Data",
   "id": "0e84172d"
  },
  {
   "cell_type": "code",
   "id": "17bab194",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def rgb_to_cmy(rgb_image):\n",
    "    # CMY = 1 - RGB\n",
    "    cmy_image = 1.0 - rgb_image\n",
    "    return cmy_image\n",
    "\n",
    "def extract_color_features(image):\n",
    "    features = []\n",
    "    # RGB features (6)\n",
    "    for channel in range(3):\n",
    "        channel_data = image[:, :, channel]\n",
    "        features.append(np.mean(channel_data))\n",
    "        features.append(np.std(channel_data))\n",
    "    \n",
    "    # CMY features (6)\n",
    "    cmy_image = rgb_to_cmy(image)\n",
    "    for channel in range(3):\n",
    "        channel_data = cmy_image[:, :, channel]\n",
    "        features.append(np.mean(channel_data))\n",
    "        features.append(np.std(channel_data))\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "def load_and_extract_features(image_dir, labels_df):\n",
    "    features_list = []\n",
    "    valid_indices = []\n",
    "    \n",
    "    for idx, row in labels_df.iterrows():\n",
    "        img_path = os.path.join(image_dir, f\"{row['id']}.jpg\")\n",
    "        \n",
    "        if os.path.exists(img_path):\n",
    "            img = Image.open(img_path)\n",
    "            img_resized = img.resize((410, 205))\n",
    "            img_array = np.array(img_resized).astype('float32') / 255.0\n",
    "            \n",
    "            features = extract_color_features(img_array)\n",
    "            features_list.append(features)\n",
    "            valid_indices.append(idx)\n",
    "        else:\n",
    "            print(f\"Warning: {img_path} not found\")\n",
    "    \n",
    "    features_array = np.array(features_list)\n",
    "    labels = labels_df.loc[valid_indices].reset_index(drop=True)\n",
    "    \n",
    "    return features_array, labels\n",
    "\n",
    "def convert_to_single_label(row):\n",
    "    if row['miner'] == 1:\n",
    "        return 'miner'\n",
    "    elif row['phoma'] == 1:\n",
    "        return 'phoma'\n",
    "    elif row['rust'] == 1:\n",
    "        return 'rust'\n",
    "    else:\n",
    "        return 'nodisease'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.Validation Set",
   "id": "2fc02a1b18d57e41"
  },
  {
   "cell_type": "code",
   "id": "fe4bc695",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder \n",
    "import pandas as pd\n",
    "\n",
    "train_label_df = pd.read_csv('dataset/train_classes.csv')\n",
    "\n",
    "train_label_df['label'] = train_label_df.apply(convert_to_single_label, axis=1)\n",
    "\n",
    "train_features, train_labels = load_and_extract_features('dataset/coffee-leaf-diseases/train/images', train_label_df)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    train_features,\n",
    "    train_labels['label'],\n",
    "    test_size=0.2,\n",
    "    stratify=train_labels['label'],\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_valid_encoded = label_encoder.transform(y_valid)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a39ab401",
   "metadata": {},
   "source": "### Hyperparameter Tuning and GridSearch"
  },
  {
   "cell_type": "code",
   "id": "c2852ade",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# ---------- Decision Tree ----------\n",
    "dt = DecisionTreeClassifier(max_features=None, random_state=123, splitter='best')\n",
    "param_grid_dt = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': list(range(1, 21)) + [None],\n",
    "    'min_samples_split': range(2, 11),\n",
    "    'min_samples_leaf': range(1, 6)\n",
    "}\n",
    "\n",
    "grid_search_dt = GridSearchCV(dt, param_grid_dt, cv=10)\n",
    "grid_search_dt.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_model_dt = grid_search_dt.best_estimator_\n",
    "print(grid_search_dt.best_params_)\n",
    "print(grid_search_dt.best_score_)\n",
    "\n",
    "# ---------- KNN ----------\n",
    "knn = KNeighborsClassifier(algorithm='auto', leaf_size=30, n_jobs=-1, p=2, weights='uniform')\n",
    "param_grid_knn = {\n",
    "    'metric': ['euclidean', 'manhattan'],\n",
    "    'n_neighbors': range(1, 21),\n",
    "}\n",
    "grid_search_knn = GridSearchCV(knn, param_grid_knn, cv=10)\n",
    "grid_search_knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_model_knn = grid_search_knn.best_estimator_\n",
    "print(grid_search_knn.best_params_)\n",
    "print(grid_search_knn.best_score_)\n",
    "\n",
    "# ---------- Logistic Regression ----------\n",
    "lr = LogisticRegression(max_iter=1000, random_state=123)\n",
    "param_grid_lr = {\n",
    "    'solver': ['lbfgs', 'saga'],\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'penalty': ['l2']\n",
    "}\n",
    "grid_search_lr = GridSearchCV(lr, param_grid_lr, cv=10, scoring='accuracy', n_jobs=-1)\n",
    "grid_search_lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_model_lr = grid_search_lr.best_estimator_\n",
    "print(grid_search_lr.best_params_)\n",
    "print(grid_search_lr.best_score_)\n",
    "\n",
    "# ---------- Neural network ----------\n",
    "nn = MLPClassifier(max_iter=5000, random_state=123)\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (100, 50)],\n",
    "    'solver': ['adam', 'lbfgs'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate_init': [0.001, 0.01]\n",
    "}\n",
    "grid_search_nn = GridSearchCV(estimator=nn, param_grid=param_grid,cv=10, scoring='accuracy', n_jobs=-1)\n",
    "grid_search_nn.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_model_nn = grid_search_nn.best_estimator_\n",
    "print(grid_search_nn.best_params_)\n",
    "print(grid_search_nn.best_score_)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "results = []\n",
    "for name, gs in [(\"Decision Tree\", grid_search_dt),\n",
    "                 (\"KNN\", grid_search_knn),\n",
    "                 (\"Logistic Regression\", grid_search_lr),\n",
    "                 (\"Neural Network\", grid_search_nn)]:\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Best Params\": gs.best_params_,\n",
    "        \"CV Score\": gs.best_score_\n",
    "    })\n",
    "pd.DataFrame(results)"
   ],
   "id": "33f6a60b286b82f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0ea0c871",
   "metadata": {},
   "source": "### Evaluation using the best parameters"
  },
  {
   "cell_type": "code",
   "id": "3fd35699",
   "metadata": {},
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# ---------- Decision Tree ----------\n",
    "y_pred_valid_dt_best = best_model_dt.predict(X_valid_scaled)\n",
    "\n",
    "print(\"\\n=== Decision Tree Overall Metrics ===\")\n",
    "print(\"Accuracy (subset accuracy):\", accuracy_score(y_valid, y_pred_valid_dt_best))\n",
    "print(\"Precision (micro):\", precision_score(y_valid, y_pred_valid_dt_best, average='micro', zero_division=0))\n",
    "print(\"Recall (micro):\", recall_score(y_valid, y_pred_valid_dt_best, average='micro', zero_division=0))\n",
    "print(\"F1-score (micro):\", f1_score(y_valid, y_pred_valid_dt_best, average='micro', zero_division=0))\n",
    "print(\"Precision (macro):\", precision_score(y_valid, y_pred_valid_dt_best, average='macro', zero_division=0))\n",
    "print(\"Recall (macro):\", recall_score(y_valid, y_pred_valid_dt_best, average='macro', zero_division=0))\n",
    "print(\"F1-score (macro):\", f1_score(y_valid, y_pred_valid_dt_best, average='macro', zero_division=0))\n",
    "\n",
    "# ---------- KNN ----------\n",
    "y_pred_valid_knn_best = best_model_knn.predict(X_valid_scaled)\n",
    "\n",
    "print(\"\\n=== KNN Overall Metrics ===\")\n",
    "print(\"Accuracy (subset accuracy):\", accuracy_score(y_valid, y_pred_valid_knn_best))\n",
    "print(\"Precision (micro):\", precision_score(y_valid, y_pred_valid_knn_best, average='micro', zero_division=0))\n",
    "print(\"Recall (micro):\", recall_score(y_valid, y_pred_valid_knn_best, average='micro', zero_division=0))\n",
    "print(\"F1-score (micro):\", f1_score(y_valid, y_pred_valid_knn_best, average='micro', zero_division=0))\n",
    "print(\"Precision (macro):\", precision_score(y_valid, y_pred_valid_knn_best, average='macro', zero_division=0))\n",
    "print(\"Recall (macro):\", recall_score(y_valid, y_pred_valid_knn_best, average='macro', zero_division=0))\n",
    "print(\"F1-score (macro):\", f1_score(y_valid, y_pred_valid_knn_best, average='macro', zero_division=0))\n",
    "\n",
    "# ---------- Logistic Regression ----------\n",
    "y_pred_valid_lr_best = best_model_lr.predict(X_valid_scaled)\n",
    "\n",
    "print(\"\\n=== Logistic Regression Overall Metrics ===\")\n",
    "print(\"Accuracy (subset accuracy):\", accuracy_score(y_valid, y_pred_valid_lr_best))\n",
    "print(\"Precision (micro):\", precision_score(y_valid, y_pred_valid_lr_best, average='micro', zero_division=0))\n",
    "print(\"Recall (micro):\", recall_score(y_valid, y_pred_valid_lr_best, average='micro', zero_division=0))\n",
    "print(\"F1-score (micro):\", f1_score(y_valid, y_pred_valid_lr_best, average='micro', zero_division=0))\n",
    "print(\"Precision (macro):\", precision_score(y_valid, y_pred_valid_lr_best, average='macro', zero_division=0))\n",
    "print(\"Recall (macro):\", recall_score(y_valid, y_pred_valid_lr_best, average='macro', zero_division=0))\n",
    "print(\"F1-score (macro):\", f1_score(y_valid, y_pred_valid_lr_best, average='macro', zero_division=0))\n",
    "\n",
    "# ---------- Neural Network ----------\n",
    "y_pred_valid_nn_best = best_model_nn.predict(X_valid_scaled)\n",
    "\n",
    "print(\"\\n=== Neural Network Overall Metrics ===\")\n",
    "print(\"Accuracy (subset accuracy):\", accuracy_score(y_valid, y_pred_valid_nn_best))\n",
    "print(\"Precision (micro):\", precision_score(y_valid, y_pred_valid_nn_best, average='micro', zero_division=0))\n",
    "print(\"Recall (micro):\", recall_score(y_valid, y_pred_valid_nn_best, average='micro', zero_division=0))\n",
    "print(\"F1-score (micro):\", f1_score(y_valid, y_pred_valid_nn_best, average='micro', zero_division=0))\n",
    "print(\"Precision (macro):\", precision_score(y_valid, y_pred_valid_nn_best, average='macro', zero_division=0))\n",
    "print(\"Recall (macro):\", recall_score(y_valid, y_pred_valid_nn_best, average='macro', zero_division=0))\n",
    "print(\"F1-score (macro):\", f1_score(y_valid, y_pred_valid_nn_best, average='macro', zero_division=0))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results_valid = []\n",
    "for name, model, y_pred in [\n",
    "    (\"Decision Tree\", best_model_dt, y_pred_valid_dt_best),\n",
    "    (\"KNN\", best_model_knn, y_pred_valid_knn_best),\n",
    "    (\"Logistic Regression\", best_model_lr, y_pred_valid_lr_best),\n",
    "    (\"Neural Network\", best_model_nn, y_pred_valid_nn_best)\n",
    "]:\n",
    "    results_valid.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(y_valid, y_pred),\n",
    "        \"Precision (micro)\": precision_score(y_valid, y_pred, average='micro', zero_division=0),\n",
    "        \"Recall (micro)\": recall_score(y_valid, y_pred, average='micro', zero_division=0),\n",
    "        \"F1-score (micro)\": f1_score(y_valid, y_pred, average='micro', zero_division=0),\n",
    "        \"Precision (macro)\": precision_score(y_valid, y_pred, average='macro', zero_division=0),\n",
    "        \"Recall (macro)\": recall_score(y_valid, y_pred, average='macro', zero_division=0),\n",
    "        \"F1_macro (macro)\": f1_score(y_valid, y_pred, average='macro', zero_division=0),\n",
    "    })\n",
    "pd.DataFrame(results_valid)"
   ],
   "id": "ec795393b65a6938",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "da570cd0",
   "metadata": {},
   "source": "### Confusion Matrix Heatmap"
  },
  {
   "cell_type": "code",
   "id": "f31d4264",
   "metadata": {},
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = sorted(y_valid.unique())\n",
    "\n",
    "# ---------- Decision Tree ----------\n",
    "cm_valid_dt_best = confusion_matrix(y_valid, y_pred_valid_dt_best)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(\n",
    "    cm_valid_dt_best,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Greens',\n",
    "    xticklabels=labels,\n",
    "    yticklabels=labels\n",
    ")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix of Valid Set - Decision Tree')\n",
    "plt.show()\n",
    "\n",
    "# ---------- KNN ----------\n",
    "cm_valid_knn_best = confusion_matrix(y_valid, y_pred_valid_knn_best)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(\n",
    "    cm_valid_knn_best,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=labels,\n",
    "    yticklabels=labels\n",
    ")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix of Valid Set - KNN')\n",
    "plt.show()\n",
    "\n",
    "# ---------- Logistic Regression ----------\n",
    "cm_valid_lr_best = confusion_matrix(y_valid, y_pred_valid_lr_best)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(\n",
    "    cm_valid_lr_best,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Purples',\n",
    "    xticklabels=labels,\n",
    "    yticklabels=labels\n",
    ")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix of Valid Set - Logistic Regression')\n",
    "plt.show()\n",
    "\n",
    "# ---------- Neural network ----------\n",
    "cm_valid_nn_best = confusion_matrix(y_valid, y_pred_valid_nn_best)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(\n",
    "    cm_valid_nn_best,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Oranges',\n",
    "    xticklabels=labels,\n",
    "    yticklabels=labels\n",
    ")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix of Valid Set - Neural Network')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f27607d5",
   "metadata": {},
   "source": "### ROC-AUC Curves"
  },
  {
   "cell_type": "code",
   "id": "2bf96747",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Decision Tree\n",
    "y_score_valid_dt_best = best_model_dt.predict_proba(X_valid_scaled)\n",
    "y_bin_valid_dt_best = label_binarize(y_valid, classes=best_model_dt.classes_)\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, class_name in enumerate(best_model_dt.classes_):\n",
    "    fpr_dt, tpr_dt, _ = roc_curve(y_bin_valid_dt_best[:, i], y_score_valid_dt_best[:, i])\n",
    "    roc_auc_dt_best = auc(fpr_dt, tpr_dt)\n",
    "    plt.plot(\n",
    "        fpr_dt,\n",
    "        tpr_dt,\n",
    "        lw=2,\n",
    "        label=f'{class_name} (AUC = {roc_auc_dt_best:.4f})'\n",
    "    )\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve (Valid Set) - Decision Tree')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ---------- KNN ----------\n",
    "y_score_valid_knn_best = best_model_knn.predict_proba(X_valid_scaled)\n",
    "y_bin_valid_knn_best = label_binarize(y_valid, classes=best_model_knn.classes_)\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, class_name in enumerate(best_model_knn.classes_):\n",
    "    fpr_knn, tpr_knn, _ = roc_curve(y_bin_valid_knn_best[:, i], y_score_valid_knn_best[:, i])\n",
    "    roc_auc_knn_best = auc(fpr_knn, tpr_knn)\n",
    "    plt.plot(\n",
    "        fpr_knn,\n",
    "        tpr_knn,\n",
    "        lw=2,\n",
    "        label=f'{class_name} (AUC = {roc_auc_knn_best:.4f})'\n",
    "    )\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve (Valid Set) - KNN')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ---------- Logistic Regression ----------\n",
    "y_score_valid_lr_best = best_model_lr.predict_proba(X_valid_scaled)\n",
    "y_bin_valid_lr_best = label_binarize(y_valid, classes=best_model_lr.classes_)\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, class_name in enumerate(best_model_lr.classes_):\n",
    "    fpr_lr, tpr_lr, _ = roc_curve(y_bin_valid_lr_best[:, i], y_score_valid_lr_best[:, i])\n",
    "    roc_auc_lr_best = auc(fpr_lr, tpr_lr)\n",
    "    plt.plot(\n",
    "        fpr_lr,\n",
    "        tpr_lr,\n",
    "        lw=2,\n",
    "        label=f'{class_name} (AUC = {roc_auc_lr_best:.4f})'\n",
    "    )\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve (Valid Set) - Logistic Regression')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ---------- Neural network ----------\n",
    "y_score_valid_nn_best = best_model_nn.predict_proba(X_valid_scaled)\n",
    "y_bin_valid_nn_best = label_binarize(y_valid, classes=best_model_nn.classes_)\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, class_name in enumerate(best_model_nn.classes_):\n",
    "    fpr_nn, tpr_nn, _ = roc_curve(y_bin_valid_nn_best[:, i], y_score_valid_nn_best[:, i])\n",
    "    roc_auc_nn_best = auc(fpr_nn, tpr_nn)\n",
    "    plt.plot(\n",
    "        fpr_nn,\n",
    "        tpr_nn,\n",
    "        lw=2,\n",
    "        label=f'{class_name} (AUC = {roc_auc_nn_best:.4f})'\n",
    "    )\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve (Valid Set) - Neural Network')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Test Set",
   "id": "ffb425a526fccfb5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_label_df = pd.read_csv('dataset/test_classes.csv')\n",
    "test_label_df['label'] = test_label_df.apply(convert_to_single_label, axis=1)\n",
    "\n",
    "test_features, test_labels = load_and_extract_features('dataset/coffee-leaf-diseases/test/images', test_label_df)\n",
    "\n",
    "y_test = test_labels['label']\n",
    "\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "X_test_scaled = scaler.transform(test_features)"
   ],
   "id": "ed8b95647ede8504",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Evaluation using the best parameters",
   "id": "25e9de8af4b952c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ---------- Decision Tree ----------\n",
    "y_pred_test_dt_best = best_model_dt.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\n=== Decision Tree Test Metrics ===\")\n",
    "print(\"Accuracy (subset accuracy):\", accuracy_score(y_test, y_pred_test_dt_best))\n",
    "print(\"Precision (micro):\", precision_score(y_test, y_pred_test_dt_best, average='micro', zero_division=0))\n",
    "print(\"Recall (micro):\", recall_score(y_test, y_pred_test_dt_best, average='micro', zero_division=0))\n",
    "print(\"F1-score (micro):\", f1_score(y_test, y_pred_test_dt_best, average='micro', zero_division=0))\n",
    "print(\"Precision (macro):\", precision_score(y_test, y_pred_test_dt_best, average='macro', zero_division=0))\n",
    "print(\"Recall (macro):\", recall_score(y_test, y_pred_test_dt_best, average='macro', zero_division=0))\n",
    "print(\"F1-score (macro):\", f1_score(y_test, y_pred_test_dt_best, average='macro', zero_division=0))\n",
    "\n",
    "# ---------- KNN ----------\n",
    "y_pred_test_knn_best = best_model_knn.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\n=== KNN Test Metrics ===\")\n",
    "print(\"Accuracy (subset accuracy):\", accuracy_score(y_test, y_pred_test_knn_best))\n",
    "print(\"Precision (micro):\", precision_score(y_test, y_pred_test_knn_best, average='micro', zero_division=0))\n",
    "print(\"Recall (micro):\", recall_score(y_test, y_pred_test_knn_best, average='micro', zero_division=0))\n",
    "print(\"F1-score (micro):\", f1_score(y_test, y_pred_test_knn_best, average='micro', zero_division=0))\n",
    "print(\"Precision (macro):\", precision_score(y_test, y_pred_test_knn_best, average='macro', zero_division=0))\n",
    "print(\"Recall (macro):\", recall_score(y_test, y_pred_test_knn_best, average='macro', zero_division=0))\n",
    "print(\"F1-score (macro):\", f1_score(y_test, y_pred_test_knn_best, average='macro', zero_division=0))\n",
    "\n",
    "# ---------- Logistic Regression ----------\n",
    "y_pred_test_lr_best = best_model_lr.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\n=== Logistic Regression Test Metrics ===\")\n",
    "print(\"Accuracy (subset accuracy):\", accuracy_score(y_test, y_pred_test_lr_best))\n",
    "print(\"Precision (micro):\", precision_score(y_test, y_pred_test_lr_best, average='micro', zero_division=0))\n",
    "print(\"Recall (micro):\", recall_score(y_test, y_pred_test_lr_best, average='micro', zero_division=0))\n",
    "print(\"F1-score (micro):\", f1_score(y_test, y_pred_test_lr_best, average='micro', zero_division=0))\n",
    "print(\"Precision (macro):\", precision_score(y_test, y_pred_test_lr_best, average='macro', zero_division=0))\n",
    "print(\"Recall (macro):\", recall_score(y_test, y_pred_test_lr_best, average='macro', zero_division=0))\n",
    "print(\"F1-score (macro):\", f1_score(y_test, y_pred_test_lr_best, average='macro', zero_division=0))\n",
    "\n",
    "# ---------- Neural Network ----------\n",
    "y_pred_test_nn_best = best_model_nn.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\n=== Neural Network Test Metrics ===\")\n",
    "print(\"Accuracy (subset accuracy):\", accuracy_score(y_test, y_pred_test_nn_best))\n",
    "print(\"Precision (micro):\", precision_score(y_test, y_pred_test_nn_best, average='micro', zero_division=0))\n",
    "print(\"Recall (micro):\", recall_score(y_test, y_pred_test_nn_best, average='micro', zero_division=0))\n",
    "print(\"F1-score (micro):\", f1_score(y_test, y_pred_test_nn_best, average='micro', zero_division=0))\n",
    "print(\"Precision (macro):\", precision_score(y_test, y_pred_test_nn_best, average='macro', zero_division=0))\n",
    "print(\"Recall (macro):\", recall_score(y_test, y_pred_test_nn_best, average='macro', zero_division=0))\n",
    "print(\"F1-score (macro):\", f1_score(y_test, y_pred_test_nn_best, average='macro', zero_division=0))"
   ],
   "id": "91e558f31d2f9358",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results_test = []\n",
    "for name, model, y_pred in [\n",
    "    (\"Decision Tree\", best_model_dt, y_pred_test_dt_best),\n",
    "    (\"KNN\", best_model_knn, y_pred_test_knn_best),\n",
    "    (\"Logistic Regression\", best_model_lr, y_pred_test_lr_best),\n",
    "    (\"Neural Network\", best_model_nn, y_pred_test_nn_best)\n",
    "]:\n",
    "    results_test.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision (micro)\": precision_score(y_test, y_pred, average='micro', zero_division=0),\n",
    "        \"Recall (micro)\": recall_score(y_test, y_pred, average='micro', zero_division=0),\n",
    "        \"F1-score (micro)\": f1_score(y_test, y_pred, average='micro', zero_division=0),\n",
    "        \"Precision (macro)\": precision_score(y_test, y_pred, average='macro', zero_division=0),\n",
    "        \"Recall (macro)\": recall_score(y_test, y_pred, average='macro', zero_division=0),\n",
    "        \"F1-score (macro)\": f1_score(y_test, y_pred, average='macro', zero_division=0),\n",
    "    })\n",
    "\n",
    "pd.DataFrame(results_test)"
   ],
   "id": "280d782ba17215f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Confusion Matrix Heatmap",
   "id": "6c48789354ec3139"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "labels = sorted(list(set(y_test)))\n",
    "\n",
    "# ---------- Decision Tree ----------\n",
    "cm_test_dt = confusion_matrix(y_test, y_pred_test_dt_best)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(\n",
    "    cm_test_dt,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Greens',\n",
    "    xticklabels=labels,\n",
    "    yticklabels=labels\n",
    ")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix of Test Set - Decision Tree')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ---------- KNN ----------\n",
    "cm_test_knn = confusion_matrix(y_test, y_pred_test_knn_best)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(\n",
    "    cm_test_knn,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=labels,\n",
    "    yticklabels=labels\n",
    ")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix of Test Set - KNN')\n",
    "plt.show()\n",
    "\n",
    "# ---------- Logistic Regression ----------\n",
    "cm_test_lr = confusion_matrix(y_test, y_pred_test_lr_best)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(\n",
    "    cm_test_lr,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Purples',\n",
    "    xticklabels=labels,\n",
    "    yticklabels=labels\n",
    ")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix of Test Set - Logistic Regression')\n",
    "plt.show()\n",
    "\n",
    "# ---------- Neural network ----------\n",
    "cm_test_nn = confusion_matrix(y_test, y_pred_test_nn_best)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(\n",
    "    cm_test_nn,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Oranges',\n",
    "    xticklabels=labels,\n",
    "    yticklabels=labels\n",
    ")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix of Test Set - Neural Network')\n",
    "plt.show()"
   ],
   "id": "e1969634cb24b0e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ROC-AUC Curves",
   "id": "43cb2bd6b0f15082"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- Decision Tree ----------\n",
    "y_score_test_dt_best = best_model_dt.predict_proba(X_test_scaled)\n",
    "y_bin_test_dt_best = label_binarize(y_test, classes=best_model_dt.classes_)\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, class_name in enumerate(best_model_dt.classes_):\n",
    "    fpr_dt, tpr_dt, _ = roc_curve(y_bin_test_dt_best[:, i], y_score_test_dt_best[:, i])\n",
    "    roc_auc_dt_best = auc(fpr_dt, tpr_dt)\n",
    "    plt.plot(fpr_dt, tpr_dt, lw=2, label=f'{class_name} (AUC = {roc_auc_dt_best:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve (Test Set) - Decision Tree')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ---------- KNN ----------\n",
    "y_score_test_knn_best = best_model_knn.predict_proba(X_test_scaled)\n",
    "y_bin_test_knn_best = label_binarize(y_test, classes=best_model_knn.classes_)\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, class_name in enumerate(best_model_knn.classes_):\n",
    "    fpr_knn, tpr_knn, _ = roc_curve(y_bin_test_knn_best[:, i], y_score_test_knn_best[:, i])\n",
    "    roc_auc_knn_best = auc(fpr_knn, tpr_knn)\n",
    "    plt.plot(fpr_knn, tpr_knn, lw=2, label=f'{class_name} (AUC = {roc_auc_knn_best:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve (Test Set) - KNN')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ---------- Logistic Regression ----------\n",
    "y_score_test_lr_best = best_model_lr.predict_proba(X_test_scaled)\n",
    "y_bin_test_lr_best = label_binarize(y_test, classes=best_model_lr.classes_)\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, class_name in enumerate(best_model_lr.classes_):\n",
    "    fpr_lr, tpr_lr, _ = roc_curve(y_bin_test_lr_best[:, i], y_score_test_lr_best[:, i])\n",
    "    roc_auc_lr_best = auc(fpr_lr, tpr_lr)\n",
    "    plt.plot(fpr_lr, tpr_lr, lw=2, label=f'{class_name} (AUC = {roc_auc_lr_best:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve (Test Set) - Logistic Regression')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ---------- Neural Network ----------\n",
    "y_score_test_nn_best = best_model_nn.predict_proba(X_test_scaled)\n",
    "y_bin_test_nn_best = label_binarize(y_test, classes=best_model_nn.classes_)\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, class_name in enumerate(best_model_nn.classes_):\n",
    "    fpr_nn, tpr_nn, _ = roc_curve(y_bin_test_nn_best[:, i], y_score_test_nn_best[:, i])\n",
    "    roc_auc_nn_best = auc(fpr_nn, tpr_nn)\n",
    "    plt.plot(fpr_nn, tpr_nn, lw=2, label=f'{class_name} (AUC = {roc_auc_nn_best:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve (Test Set) - Neural Network')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "7487e535f98d6bfb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Combined Set (Validation Set + Test Set)\n",
   "id": "e97cbc5e318cc03c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_label_df = pd.read_csv('dataset/train_classes.csv')\n",
    "test_label_df  = pd.read_csv('dataset/test_classes.csv')\n",
    "\n",
    "train_label_df['label'] = train_label_df.apply(convert_to_single_label, axis=1)\n",
    "test_label_df['label']  = test_label_df.apply(convert_to_single_label, axis=1)\n",
    "\n",
    "train_features, train_labels = load_and_extract_features('dataset/coffee-leaf-diseases/train/images', train_label_df)\n",
    "test_features, test_labels = load_and_extract_features('dataset/coffee-leaf-diseases/test/images', test_label_df)\n",
    "\n",
    "all_features = np.vstack([train_features, test_features])\n",
    "all_labels   = pd.concat([train_labels['label'], test_labels['label']], axis=0, ignore_index=True)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    all_features,\n",
    "    all_labels,\n",
    "    test_size=0.2,\n",
    "    stratify=all_labels,\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_valid_encoded = label_encoder.transform(y_valid)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)"
   ],
   "id": "885da521c6ef1a77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Hyperparameter Tuning and Grid Search",
   "id": "1e11ced7058b3e26"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ---------- Decision Tree ----------\n",
    "dt = DecisionTreeClassifier(max_features=None, random_state=123, splitter='best')\n",
    "param_grid_dt = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': list(range(1, 21)) + [None],\n",
    "    'min_samples_split': range(2, 11),\n",
    "    'min_samples_leaf': range(1, 6)\n",
    "}\n",
    "grid_search_dt = GridSearchCV(dt, param_grid_dt, cv=10)\n",
    "grid_search_dt.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_model_dt = grid_search_dt.best_estimator_\n",
    "print(\"Decision Tree best params:\", grid_search_dt.best_params_)\n",
    "print(\"Decision Tree CV score:\", grid_search_dt.best_score_)\n",
    "\n",
    "# ---------- KNN ----------\n",
    "knn = KNeighborsClassifier(algorithm='auto', leaf_size=30, n_jobs=-1, p=2, weights='uniform')\n",
    "param_grid_knn = {\n",
    "    'metric': ['euclidean', 'manhattan'],\n",
    "    'n_neighbors': range(1, 21),\n",
    "}\n",
    "grid_search_knn = GridSearchCV(knn, param_grid_knn, cv=10)\n",
    "grid_search_knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_model_knn = grid_search_knn.best_estimator_\n",
    "print(\"KNN best params:\", grid_search_knn.best_params_)\n",
    "print(\"KNN CV score:\", grid_search_knn.best_score_)\n",
    "\n",
    "# ---------- Logistic Regression ----------\n",
    "lr = LogisticRegression(max_iter=1000, random_state=123)\n",
    "param_grid_lr = {\n",
    "    'solver': ['lbfgs', 'saga'],\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'penalty': ['l2']\n",
    "}\n",
    "grid_search_lr = GridSearchCV(lr, param_grid_lr, cv=10, scoring='accuracy', n_jobs=-1)\n",
    "grid_search_lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_model_lr = grid_search_lr.best_estimator_\n",
    "print(\"Logistic Regression best params:\", grid_search_lr.best_params_)\n",
    "print(\"Logistic Regression CV score:\", grid_search_lr.best_score_)\n",
    "\n",
    "# ---------- Neural Network ----------\n",
    "nn = MLPClassifier(max_iter=5000, random_state=123)\n",
    "param_grid_nn = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (100, 50)],\n",
    "    'solver': ['adam', 'lbfgs'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate_init': [0.001, 0.01]\n",
    "}\n",
    "\n",
    "grid_search_nn = GridSearchCV(nn, param_grid_nn, cv=10, scoring='accuracy', n_jobs=-1)\n",
    "grid_search_nn.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_model_nn = grid_search_nn.best_estimator_\n",
    "print(\"Neural Network best params:\", grid_search_nn.best_params_)\n",
    "print(\"Neural Network CV score:\", grid_search_nn.best_score_)"
   ],
   "id": "8ac4af5f314e2d0b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "results_combine = []\n",
    "for name, gs in [(\"Decision Tree\", grid_search_dt),\n",
    "                 (\"KNN\", grid_search_knn),\n",
    "                 (\"Logistic Regression\", grid_search_lr),\n",
    "                 (\"Neural Network\", grid_search_nn)]:\n",
    "    results_combine.append({\n",
    "        \"Model\": name,\n",
    "        \"Best Params\": gs.best_params_,\n",
    "        \"CV Score\": gs.best_score_\n",
    "    })\n",
    "\n",
    "pd.DataFrame(results_combine)"
   ],
   "id": "1b15b78512ac6f45",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluation using the best parameters",
   "id": "34401f7835aa2e25"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ---------- Decision Tree ----------\n",
    "y_pred_valid_dt_best = best_model_dt.predict(X_valid_scaled)\n",
    "\n",
    "print(\"\\n=== Decision Tree Overall Metrics (Combine) ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_valid, y_pred_valid_dt_best))\n",
    "print(\"Precision (micro):\", precision_score(y_valid, y_pred_valid_dt_best, average='micro', zero_division=0))\n",
    "print(\"Recall (micro):\", recall_score(y_valid, y_pred_valid_dt_best, average='micro', zero_division=0))\n",
    "print(\"F1-score (micro):\", f1_score(y_valid, y_pred_valid_dt_best, average='micro', zero_division=0))\n",
    "print(\"Precision (macro):\", precision_score(y_valid, y_pred_valid_dt_best, average='macro', zero_division=0))\n",
    "print(\"Recall (macro):\", recall_score(y_valid, y_pred_valid_dt_best, average='macro', zero_division=0))\n",
    "print(\"F1-score (macro):\", f1_score(y_valid, y_pred_valid_dt_best, average='macro', zero_division=0))\n",
    "\n",
    "# ---------- KNN ----------\n",
    "y_pred_valid_knn_best = best_model_knn.predict(X_valid_scaled)\n",
    "\n",
    "print(\"\\n=== KNN Overall Metrics (Combine) ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_valid, y_pred_valid_knn_best))\n",
    "print(\"Precision (micro):\", precision_score(y_valid, y_pred_valid_knn_best, average='micro', zero_division=0))\n",
    "print(\"Recall (micro):\", recall_score(y_valid, y_pred_valid_knn_best, average='micro', zero_division=0))\n",
    "print(\"F1-score (micro):\", f1_score(y_valid, y_pred_valid_knn_best, average='micro', zero_division=0))\n",
    "print(\"Precision (macro):\", precision_score(y_valid, y_pred_valid_knn_best, average='macro', zero_division=0))\n",
    "print(\"Recall (macro):\", recall_score(y_valid, y_pred_valid_knn_best, average='macro', zero_division=0))\n",
    "print(\"F1-score (macro):\", f1_score(y_valid, y_pred_valid_knn_best, average='macro', zero_division=0))\n",
    "\n",
    "# ---------- Logistic Regression ----------\n",
    "y_pred_valid_lr_best = best_model_lr.predict(X_valid_scaled)\n",
    "\n",
    "print(\"\\n=== Logistic Regression Overall Metrics (Combine) ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_valid, y_pred_valid_lr_best))\n",
    "print(\"Precision (micro):\", precision_score(y_valid, y_pred_valid_lr_best, average='micro', zero_division=0))\n",
    "print(\"Recall (micro):\", recall_score(y_valid, y_pred_valid_lr_best, average='micro', zero_division=0))\n",
    "print(\"F1-score (micro):\", f1_score(y_valid, y_pred_valid_lr_best, average='micro', zero_division=0))\n",
    "print(\"Precision (macro):\", precision_score(y_valid, y_pred_valid_lr_best, average='macro', zero_division=0))\n",
    "print(\"Recall (macro):\", recall_score(y_valid, y_pred_valid_lr_best, average='macro', zero_division=0))\n",
    "print(\"F1-score (macro):\", f1_score(y_valid, y_pred_valid_lr_best, average='macro', zero_division=0))\n",
    "\n",
    "# ---------- Neural Network ----------\n",
    "y_pred_valid_nn_best = best_model_nn.predict(X_valid_scaled)\n",
    "\n",
    "print(\"\\n=== Neural Network Overall Metrics (Combine) ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_valid, y_pred_valid_nn_best))\n",
    "print(\"Precision (micro):\", precision_score(y_valid, y_pred_valid_nn_best, average='micro', zero_division=0))\n",
    "print(\"Recall (micro):\", recall_score(y_valid, y_pred_valid_nn_best, average='micro', zero_division=0))\n",
    "print(\"F1-score (micro):\", f1_score(y_valid, y_pred_valid_nn_best, average='micro', zero_division=0))\n",
    "print(\"Precision (macro):\", precision_score(y_valid, y_pred_valid_nn_best, average='macro', zero_division=0))\n",
    "print(\"Recall (macro):\", recall_score(y_valid, y_pred_valid_nn_best, average='macro', zero_division=0))\n",
    "print(\"F1-score (macro):\", f1_score(y_valid, y_pred_valid_nn_best, average='macro', zero_division=0))"
   ],
   "id": "13934284380b8a88",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results_valid_combine = []\n",
    "for name, y_pred in [\n",
    "    (\"Decision Tree\", y_pred_valid_dt_best),\n",
    "    (\"KNN\", y_pred_valid_knn_best),\n",
    "    (\"Logistic Regression\", y_pred_valid_lr_best),\n",
    "    (\"Neural Network\", y_pred_valid_nn_best)\n",
    "]:\n",
    "    results_valid_combine.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(y_valid, y_pred),\n",
    "        \"Precision (micro)\": precision_score(y_valid, y_pred, average='micro', zero_division=0),\n",
    "        \"Recall (micro)\": recall_score(y_valid, y_pred, average='micro', zero_division=0),\n",
    "        \"F1-score (micro)\": f1_score(y_valid, y_pred, average='micro', zero_division=0),\n",
    "        \"Precision (macro)\": precision_score(y_valid, y_pred, average='macro', zero_division=0),\n",
    "        \"Recall (macro)\": recall_score(y_valid, y_pred, average='macro', zero_division=0),\n",
    "        \"F1-score (macro)\": f1_score(y_valid, y_pred, average='macro', zero_division=0),\n",
    "    })\n",
    "pd.DataFrame(results_valid_combine)"
   ],
   "id": "ee15c7aab45898b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Confusion Matrix Heatmap",
   "id": "e526ce57ec04aa76"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "labels = sorted(y_valid.unique())\n",
    "\n",
    "# ---------- Decision Tree ----------\n",
    "cm_valid_dt_best = confusion_matrix(y_valid, y_pred_valid_dt_best)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm_valid_dt_best, annot=True, fmt='d', cmap='Greens',\n",
    "            xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix (Combine Valid) - Decision Tree')\n",
    "plt.show()\n",
    "\n",
    "# ---------- KNN ----------\n",
    "cm_valid_knn_best = confusion_matrix(y_valid, y_pred_valid_knn_best)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm_valid_knn_best, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix (Combine Valid) - KNN')\n",
    "plt.show()\n",
    "\n",
    "# ---------- Logistic Regression ----------\n",
    "cm_valid_lr_best = confusion_matrix(y_valid, y_pred_valid_lr_best)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm_valid_lr_best, annot=True, fmt='d', cmap='Purples',\n",
    "            xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix (Combine Valid) - Logistic Regression')\n",
    "plt.show()\n",
    "\n",
    "# ---------- Neural Network ----------\n",
    "cm_valid_nn_best = confusion_matrix(y_valid, y_pred_valid_nn_best)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm_valid_nn_best, annot=True, fmt='d', cmap='Oranges',\n",
    "            xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix (Combine Valid) - Neural Network')\n",
    "plt.show()"
   ],
   "id": "b09d951d91411e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ROC-AUC Curves",
   "id": "cf2e9e9f3a3b1aef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "labels = sorted(y_valid.unique())\n",
    "\n",
    "# ---------- Decision Tree ----------\n",
    "y_score_valid_dt_best = best_model_dt.predict_proba(X_valid_scaled)\n",
    "y_bin_valid_dt_best = label_binarize(y_valid, classes=best_model_dt.classes_)\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, class_name in enumerate(best_model_dt.classes_):\n",
    "    fpr_dt, tpr_dt, _ = roc_curve(y_bin_valid_dt_best[:, i], y_score_valid_dt_best[:, i])\n",
    "    roc_auc_dt_best = auc(fpr_dt, tpr_dt)\n",
    "    plt.plot(fpr_dt, tpr_dt, lw=2, label=f'{class_name} (AUC = {roc_auc_dt_best:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve (Combine Valid) - Decision Tree')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ---------- KNN ----------\n",
    "y_score_valid_knn_best = best_model_knn.predict_proba(X_valid_scaled)\n",
    "y_bin_valid_knn_best = label_binarize(y_valid, classes=best_model_knn.classes_)\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, class_name in enumerate(best_model_knn.classes_):\n",
    "    fpr_knn, tpr_knn, _ = roc_curve(y_bin_valid_knn_best[:, i], y_score_valid_knn_best[:, i])\n",
    "    roc_auc_knn_best = auc(fpr_knn, tpr_knn)\n",
    "    plt.plot(fpr_knn, tpr_knn, lw=2, label=f'{class_name} (AUC = {roc_auc_knn_best:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve (Combine Valid) - KNN')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ---------- Logistic Regression ----------\n",
    "y_score_valid_lr_best = best_model_lr.predict_proba(X_valid_scaled)\n",
    "y_bin_valid_lr_best = label_binarize(y_valid, classes=best_model_lr.classes_)\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, class_name in enumerate(best_model_lr.classes_):\n",
    "    fpr_lr, tpr_lr, _ = roc_curve(y_bin_valid_lr_best[:, i], y_score_valid_lr_best[:, i])\n",
    "    roc_auc_lr_best = auc(fpr_lr, tpr_lr)\n",
    "    plt.plot(fpr_lr, tpr_lr, lw=2, label=f'{class_name} (AUC = {roc_auc_lr_best:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve (Combine Valid) - Logistic Regression')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ---------- Neural Network ----------\n",
    "y_score_valid_nn_best = best_model_nn.predict_proba(X_valid_scaled)\n",
    "y_bin_valid_nn_best = label_binarize(y_valid, classes=best_model_nn.classes_)\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, class_name in enumerate(best_model_nn.classes_):\n",
    "    fpr_nn, tpr_nn, _ = roc_curve(y_bin_valid_nn_best[:, i], y_score_valid_nn_best[:, i])\n",
    "    roc_auc_nn_best = auc(fpr_nn, tpr_nn)\n",
    "    plt.plot(fpr_nn, tpr_nn, lw=2, label=f'{class_name} (AUC = {roc_auc_nn_best:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve (Combine Valid) - Neural Network')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "7265bb7aade60f70",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
