{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "20a06fc4",
      "metadata": {},
      "source": [
        "# Coffee Leaf Diseases Prediction\n",
        "\n",
        "## Overview\n",
        "This notebook is a reproduction of the coffee leaf disease classification method described in the research paper below, using machine learning techniques with RGB and CMY color features.\n",
        "\n",
        "## References\n",
        "\n",
        "### Research Paper\n",
        "- **Title**: Comparative Analysis of the Performance of the Decision Tree and K-Nearest Neighbors Methods in Classifying Coffee Leaf Diseases\n",
        "- **Authors**: Adie Suryadi, Murhaban Murhaban, Rivansyah Suhendra\n",
        "- **Published in**: Department of Information Technology, Teuku Umar University, Indonesia\n",
        "- **URL**: [https://aptikom-journal.id/conferenceseries/article/view/649/272](https://aptikom-journal.id/conferenceseries/article/view/649/272)\n",
        "\n",
        "### Dataset\n",
        "- **Dataset**: Coffee Leaf Diseases\n",
        "- **Source**: Kaggle\n",
        "- **URL**: [https://www.kaggle.com/datasets/badasstechie/coffee-leaf-diseases/code](https://www.kaggle.com/datasets/badasstechie/coffee-leaf-diseases/code)\n",
        "\n",
        "## Methodology\n",
        "This implementation extracts color-based features from coffee leaf images:\n",
        "- **RGB features**: Mean and standard deviation for each R, G, B channel (6 features)\n",
        "- **CMY features**: Mean and standard deviation for each C, M, Y channel (6 features)\n",
        "- **Total**: 12 color-based features per image\n",
        "\n",
        "The features are then used to classify coffee leaves into four categories:\n",
        "- Miner\n",
        "- Phoma\n",
        "- Rust\n",
        "- No disease"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e84172d",
      "metadata": {},
      "source": [
        "## Preprocessing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17bab194",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def rgb_to_cmy(rgb_image):\n",
        "    # CMY = 1 - RGB\n",
        "    cmy_image = 1.0 - rgb_image\n",
        "    return cmy_image\n",
        "\n",
        "def extract_color_features(image):\n",
        "    features = []\n",
        "    \n",
        "    # RGB features (6)\n",
        "    for channel in range(3):  # R, G, B\n",
        "        channel_data = image[:, :, channel]\n",
        "        features.append(np.mean(channel_data))  # Mean\n",
        "        features.append(np.std(channel_data))   # Standard deviation\n",
        "    \n",
        "    # CMY features (6)\n",
        "    cmy_image = rgb_to_cmy(image)\n",
        "    for channel in range(3):  # C, M, Y\n",
        "        channel_data = cmy_image[:, :, channel]\n",
        "        features.append(np.mean(channel_data))  # Mean\n",
        "        features.append(np.std(channel_data))   # Standard deviation\n",
        "    \n",
        "    return np.array(features)\n",
        "\n",
        "def load_and_extract_features(image_dir, labels_df):\n",
        "    features_list = []\n",
        "    valid_indices = []\n",
        "    \n",
        "    for idx, row in labels_df.iterrows():\n",
        "        img_path = os.path.join(image_dir, f\"{row['id']}.jpg\")\n",
        "        \n",
        "        if os.path.exists(img_path):\n",
        "            img = Image.open(img_path)\n",
        "            img_resized = img.resize((410, 205)) # resize to 410x205\n",
        "            img_array = np.array(img_resized).astype('float32') / 255.0 # normalize \n",
        "            \n",
        "            features = extract_color_features(img_array)\n",
        "            features_list.append(features)\n",
        "            valid_indices.append(idx)\n",
        "        else:\n",
        "            print(f\"Warning: {img_path} not found\")\n",
        "    \n",
        "    features_array = np.array(features_list)\n",
        "    labels = labels_df.loc[valid_indices].reset_index(drop=True)\n",
        "    \n",
        "    return features_array, labels\n",
        "\n",
        "def convert_to_single_label(row):\n",
        "    if row['miner'] == 1:\n",
        "        return 'miner'\n",
        "    elif row['phoma'] == 1:\n",
        "        return 'phoma'\n",
        "    elif row['rust'] == 1:\n",
        "        return 'rust'\n",
        "    else:\n",
        "        return 'nodisease'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe4bc695",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder \n",
        "import pandas as pd\n",
        "\n",
        "train_label_df = pd.read_csv('dataset/train_classes.csv')\n",
        "train_label_df['label'] = train_label_df.apply(convert_to_single_label, axis=1)\n",
        "test_label_df = pd.read_csv('dataset/test_classes.csv')\n",
        "test_label_df['label'] = test_label_df.apply(convert_to_single_label, axis=1)\n",
        "\n",
        "train_features, train_labels = load_and_extract_features('dataset/coffee-leaf-diseases/train/images', train_label_df)\n",
        "test_features, test_labels = load_and_extract_features('dataset/coffee-leaf-diseases/test/images', test_label_df)\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    train_features, \n",
        "    train_labels['label'],\n",
        "    test_size=0.2,\n",
        "    stratify=train_labels['label'],\n",
        "    random_state=123\n",
        ")\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_valid_encoded = label_encoder.transform(y_valid)\n",
        "test_labels_encoded = label_encoder.transform(test_labels['label'])\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_valid_scaled = scaler.transform(X_valid)\n",
        "test_features_scaled = scaler.transform(test_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a39ab401",
      "metadata": {},
      "source": [
        "## Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2852ade",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# ---------- Decision Tree ----------\n",
        "dt = DecisionTreeClassifier(max_features=None, random_state=123, splitter='best')\n",
        "param_grid_dt = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': list(range(1, 21)) + [None],\n",
        "    'min_samples_split': range(2, 11),\n",
        "    'min_samples_leaf': range(1, 6)\n",
        "}\n",
        "grid_search_dt = GridSearchCV(dt, param_grid_dt, cv=10)\n",
        "grid_search_dt.fit(X_train_scaled, y_train_encoded)\n",
        "\n",
        "best_model_dt = grid_search_dt.best_estimator_\n",
        "print(grid_search_dt.best_params_)\n",
        "print(grid_search_dt.best_score_)\n",
        "\n",
        "# ---------- KNN ----------\n",
        "knn = KNeighborsClassifier(algorithm='auto', leaf_size=30, n_jobs=-1, p=2, weights='uniform')\n",
        "param_grid_knn = {\n",
        "    'metric': ['euclidean', 'manhattan'],\n",
        "    'n_neighbors': range(1, 21),\n",
        "}\n",
        "grid_search_knn = GridSearchCV(knn, param_grid_knn, cv=10)\n",
        "grid_search_knn.fit(X_train_scaled, y_train_encoded)\n",
        "\n",
        "best_model_knn = grid_search_knn.best_estimator_\n",
        "print(grid_search_knn.best_params_)\n",
        "print(grid_search_knn.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fdad833",
      "metadata": {},
      "source": [
        "The best model for Decision Tree goes with below parameter:\n",
        "- criterion: 'entropy'\n",
        "- max_depth: 13\n",
        "- min_samples_leaf: 1\n",
        "- min_samples_split: 2\n",
        "\n",
        "The best model for KNN goes with below parameter:\n",
        "- metric: 'euclidean'\n",
        "- n_neighbors: 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fd966d1",
      "metadata": {},
      "source": [
        "## Find the Best Model\n",
        "### Using the parameters described in the paper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65e542f2",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# ---------- Evaluation on Validation Set ----------\n",
        "# ---------- Decision Tree ----------\n",
        "dt = DecisionTreeClassifier(\n",
        "    criterion='gini',\n",
        "    max_depth=None,\n",
        "    max_features=None,\n",
        "    min_samples_leaf=1,\n",
        "    min_samples_split=2,\n",
        "    random_state=123,\n",
        "    splitter='best'\n",
        ")\n",
        "dt.fit(X_train_scaled, y_train_encoded)\n",
        "y_pred_valid_dt = dt.predict(X_valid_scaled)\n",
        "\n",
        "print(\"\\n=== Decision Tree Overall Metrics ===\")\n",
        "print(\"Accuracy (subset accuracy):\", accuracy_score(y_valid_encoded, y_pred_valid_dt))\n",
        "print(\"Precision (micro):\", precision_score(y_valid_encoded, y_pred_valid_dt, average='micro', zero_division=0))\n",
        "print(\"Recall (micro):\", recall_score(y_valid_encoded, y_pred_valid_dt, average='micro', zero_division=0))\n",
        "print(\"F1-score (micro):\", f1_score(y_valid_encoded, y_pred_valid_dt, average='micro', zero_division=0))\n",
        "print(\"Precision (macro):\", precision_score(y_valid_encoded, y_pred_valid_dt, average='macro', zero_division=0))\n",
        "print(\"Recall (macro):\", recall_score(y_valid_encoded, y_pred_valid_dt, average='macro', zero_division=0))\n",
        "print(\"F1-score (macro):\", f1_score(y_valid_encoded, y_pred_valid_dt, average='macro', zero_division=0))\n",
        "\n",
        "# ---------- KNN ----------\n",
        "knn = KNeighborsClassifier(\n",
        "    algorithm='auto',\n",
        "    leaf_size=30,\n",
        "    metric='minkowski',\n",
        "    n_jobs=-1,\n",
        "    n_neighbors=5,\n",
        "    p=2,\n",
        "    weights='uniform'\n",
        ")\n",
        "knn.fit(X_train_scaled, y_train_encoded)\n",
        "y_pred_valid_knn = knn.predict(X_valid_scaled)\n",
        "\n",
        "print(\"\\n=== KNN Overall Metrics ===\")\n",
        "print(\"Accuracy (subset accuracy):\", accuracy_score(y_valid_encoded, y_pred_valid_knn))\n",
        "print(\"Precision (micro):\", precision_score(y_valid_encoded, y_pred_valid_knn, average='micro', zero_division=0))\n",
        "print(\"Recall (micro):\", recall_score(y_valid_encoded, y_pred_valid_knn, average='micro', zero_division=0))\n",
        "print(\"F1-score (micro):\", f1_score(y_valid_encoded, y_pred_valid_knn, average='micro', zero_division=0))\n",
        "print(\"Precision (macro):\", precision_score(y_valid_encoded, y_pred_valid_knn, average='macro', zero_division=0))\n",
        "print(\"Recall (macro):\", recall_score(y_valid_encoded, y_pred_valid_knn, average='macro', zero_division=0))\n",
        "print(\"F1-score (macro):\", f1_score(y_valid_encoded, y_pred_valid_knn, average='macro', zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "765f85e6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---------- Evaluation on Test Set ----------\n",
        "# ---------- Decision Tree ----------\n",
        "y_pred_test_dt = dt.predict(test_features_scaled)\n",
        "\n",
        "print(\"\\n=== Decision Tree Overall Metrics ===\")\n",
        "print(\"Accuracy (subset accuracy):\", accuracy_score(test_labels_encoded, y_pred_test_dt))\n",
        "print(\"Precision (micro):\", precision_score(test_labels_encoded, y_pred_test_dt, average='micro', zero_division=0))\n",
        "print(\"Recall (micro):\", recall_score(test_labels_encoded, y_pred_test_dt, average='micro', zero_division=0))\n",
        "print(\"F1-score (micro):\", f1_score(test_labels_encoded, y_pred_test_dt, average='micro', zero_division=0))\n",
        "print(\"Precision (macro):\", precision_score(test_labels_encoded, y_pred_test_dt, average='macro', zero_division=0))\n",
        "print(\"Recall (macro):\", recall_score(test_labels_encoded, y_pred_test_dt, average='macro', zero_division=0))\n",
        "print(\"F1-score (macro):\", f1_score(test_labels_encoded, y_pred_test_dt, average='macro', zero_division=0))\n",
        "\n",
        "# ---------- KNN ----------\n",
        "y_pred_test_knn = knn.predict(test_features_scaled)\n",
        "\n",
        "print(\"\\n=== KNN Overall Metrics ===\")\n",
        "print(\"Accuracy (subset accuracy):\", accuracy_score(test_labels_encoded, y_pred_test_knn))\n",
        "print(\"Precision (micro):\", precision_score(test_labels_encoded, y_pred_test_knn, average='micro', zero_division=0))\n",
        "print(\"Recall (micro):\", recall_score(test_labels_encoded, y_pred_test_knn, average='micro', zero_division=0))\n",
        "print(\"F1-score (micro):\", f1_score(test_labels_encoded, y_pred_test_knn, average='micro', zero_division=0))\n",
        "print(\"Precision (macro):\", precision_score(test_labels_encoded, y_pred_test_knn, average='macro', zero_division=0))\n",
        "print(\"Recall (macro):\", recall_score(test_labels_encoded, y_pred_test_knn, average='macro', zero_division=0))\n",
        "print(\"F1-score (macro):\", f1_score(test_labels_encoded, y_pred_test_knn, average='macro', zero_division=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0666001",
      "metadata": {},
      "source": [
        "#### Confusion Matrix Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "052b59f5",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "labels = sorted(y_valid.unique())\n",
        "\n",
        "def plot_confusion_matrix(actual, predict, model_type, target):\n",
        "    cm = confusion_matrix(actual, predict)\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(\n",
        "        cm,\n",
        "        annot=True,\n",
        "        fmt='d',\n",
        "        cmap='Greens',\n",
        "        xticklabels=labels,\n",
        "        yticklabels=labels\n",
        "    )\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.title(f'Confusion Matrix of {target} - {model_type}')\n",
        "    plt.show()\n",
        "\n",
        "# Desicion Tree\n",
        "plot_confusion_matrix(y_valid_encoded, y_pred_valid_dt, 'Decision Tree', 'Validation Set')\n",
        "plot_confusion_matrix(test_labels_encoded, y_pred_test_dt, 'Decision Tree', 'Test Set')\n",
        "\n",
        "# KNN\n",
        "plot_confusion_matrix(y_valid_encoded, y_pred_valid_knn, 'KNN', 'Validation Set')\n",
        "plot_confusion_matrix(test_labels_encoded, y_pred_test_knn, 'KNN', 'Test Set')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8ae91ce",
      "metadata": {},
      "source": [
        "#### ROC-AUC Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb565b4a",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "def plot_roc_curve(model, predict_target, actual, model_type, target_name):\n",
        "    y_score = model.predict_proba(predict_target)\n",
        "    y_bin = label_binarize(actual, classes=label_encoder.classes_)\n",
        "    all_auc = []\n",
        "    \n",
        "    plt.figure(figsize=(8, 6))\n",
        "    for i, class_name in enumerate(label_encoder.classes_):\n",
        "        fpr_dt, tpr_dt, _ = roc_curve(y_bin[:, i], y_score[:, i])\n",
        "        roc_auc_dt = auc(fpr_dt, tpr_dt)\n",
        "        all_auc.append(roc_auc_dt)\n",
        "        \n",
        "        plt.plot(\n",
        "            fpr_dt,\n",
        "            tpr_dt,\n",
        "            lw=2,\n",
        "            label=f'{class_name} (AUC = {roc_auc_dt:.4f})'\n",
        "        )\n",
        "        \n",
        "    marco_auc = sum(all_auc) / len(all_auc)\n",
        "    \n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'{model_type} ROC Curve ({target_name})\\nOverall Marco-AUC: {marco_auc:.4f}')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "\n",
        "# Decision Tree\n",
        "plot_roc_curve(dt, X_valid_scaled, y_valid, 'Decision Tree', 'Validation Set')\n",
        "plot_roc_curve(dt, test_features_scaled, test_labels['label'], 'Decision Tree', 'Test Set')\n",
        "\n",
        "# KNN\n",
        "plot_roc_curve(knn, X_valid_scaled, y_valid, 'KNN', 'Validation Set')\n",
        "plot_roc_curve(knn, test_features_scaled, test_labels['label'], 'KNN', 'Test Set')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ea0c871",
      "metadata": {},
      "source": [
        "### Using the best parameters from CV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fd35699",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---------- Evaluation on Validation Set ----------\n",
        "# ---------- Decision Tree ----------\n",
        "y_pred_valid_dt_best = best_model_dt.predict(X_valid_scaled)\n",
        "\n",
        "print(\"\\n=== Decision Tree Overall Metrics ===\")\n",
        "print(\"Accuracy (subset accuracy):\", accuracy_score(y_valid_encoded, y_pred_valid_dt_best))\n",
        "print(\"Precision (micro):\", precision_score(y_valid_encoded, y_pred_valid_dt_best, average='micro', zero_division=0))\n",
        "print(\"Recall (micro):\", recall_score(y_valid_encoded, y_pred_valid_dt_best, average='micro', zero_division=0))\n",
        "print(\"F1-score (micro):\", f1_score(y_valid_encoded, y_pred_valid_dt_best, average='micro', zero_division=0))\n",
        "print(\"Precision (macro):\", precision_score(y_valid_encoded, y_pred_valid_dt_best, average='macro', zero_division=0))\n",
        "print(\"Recall (macro):\", recall_score(y_valid_encoded, y_pred_valid_dt_best, average='macro', zero_division=0))\n",
        "print(\"F1-score (macro):\", f1_score(y_valid_encoded, y_pred_valid_dt_best, average='macro', zero_division=0))\n",
        "\n",
        "# ---------- KNN ----------\n",
        "y_pred_valid_knn_best = best_model_knn.predict(X_valid_scaled)\n",
        "\n",
        "print(\"\\n=== KNN Overall Metrics ===\")\n",
        "print(\"Accuracy (subset accuracy):\", accuracy_score(y_valid_encoded, y_pred_valid_knn_best))\n",
        "print(\"Precision (micro):\", precision_score(y_valid_encoded, y_pred_valid_knn_best, average='micro', zero_division=0))\n",
        "print(\"Recall (micro):\", recall_score(y_valid_encoded, y_pred_valid_knn_best, average='micro', zero_division=0))\n",
        "print(\"F1-score (micro):\", f1_score(y_valid_encoded, y_pred_valid_knn_best, average='micro', zero_division=0))\n",
        "print(\"Precision (macro):\", precision_score(y_valid_encoded, y_pred_valid_knn_best, average='macro', zero_division=0))\n",
        "print(\"Recall (macro):\", recall_score(y_valid_encoded, y_pred_valid_knn_best, average='macro', zero_division=0))\n",
        "print(\"F1-score (macro):\", f1_score(y_valid_encoded, y_pred_valid_knn_best, average='macro', zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80d2f2cc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---------- Evaluation on Test Set ----------\n",
        "# ---------- Decision Tree ----------\n",
        "y_pred_test_dt_best = best_model_dt.predict(test_features_scaled)\n",
        "\n",
        "print(\"\\n=== Decision Tree Overall Metrics ===\")\n",
        "print(\"Accuracy (subset accuracy):\", accuracy_score(test_labels_encoded, y_pred_test_dt_best))\n",
        "print(\"Precision (micro):\", precision_score(test_labels_encoded, y_pred_test_dt_best, average='micro', zero_division=0))\n",
        "print(\"Recall (micro):\", recall_score(test_labels_encoded, y_pred_test_dt_best, average='micro', zero_division=0))\n",
        "print(\"F1-score (micro):\", f1_score(test_labels_encoded, y_pred_test_dt_best, average='micro', zero_division=0))\n",
        "print(\"Precision (macro):\", precision_score(test_labels_encoded, y_pred_test_dt_best, average='macro', zero_division=0))\n",
        "print(\"Recall (macro):\", recall_score(test_labels_encoded, y_pred_test_dt_best, average='macro', zero_division=0))\n",
        "print(\"F1-score (macro):\", f1_score(test_labels_encoded, y_pred_test_dt_best, average='macro', zero_division=0))\n",
        "\n",
        "# ---------- KNN ----------\n",
        "y_pred_test_knn_best = best_model_knn.predict(test_features_scaled)\n",
        "\n",
        "print(\"\\n=== KNN Overall Metrics ===\")\n",
        "print(\"Accuracy (subset accuracy):\", accuracy_score(test_labels_encoded, y_pred_test_knn_best))\n",
        "print(\"Precision (micro):\", precision_score(test_labels_encoded, y_pred_test_knn_best, average='micro', zero_division=0))\n",
        "print(\"Recall (micro):\", recall_score(test_labels_encoded, y_pred_test_knn_best, average='micro', zero_division=0))\n",
        "print(\"F1-score (micro):\", f1_score(test_labels_encoded, y_pred_test_knn_best, average='micro', zero_division=0))\n",
        "print(\"Precision (macro):\", precision_score(test_labels_encoded, y_pred_test_knn_best, average='macro', zero_division=0))\n",
        "print(\"Recall (macro):\", recall_score(test_labels_encoded, y_pred_test_knn_best, average='macro', zero_division=0))\n",
        "print(\"F1-score (macro):\", f1_score(test_labels_encoded, y_pred_test_knn_best, average='macro', zero_division=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da570cd0",
      "metadata": {},
      "source": [
        "#### Confusion Matrix Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f31d4264",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Decision Tree\n",
        "plot_confusion_matrix(y_valid_encoded, y_pred_valid_dt_best, 'Decision Tree', 'Validation Set')\n",
        "plot_confusion_matrix(test_labels_encoded, y_pred_test_dt_best, 'Decision Tree', 'Test Set')\n",
        "\n",
        "# KNN\n",
        "plot_confusion_matrix(y_valid_encoded, y_pred_valid_knn_best, 'KNN', 'Validation Set')\n",
        "plot_confusion_matrix(test_labels_encoded, y_pred_test_knn_best, 'KNN', 'Test Set')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f27607d5",
      "metadata": {},
      "source": [
        "#### ROC-AUC Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bf96747",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Decision Tree\n",
        "plot_roc_curve(best_model_dt, X_valid_scaled, y_valid, 'Decision Tree', 'Validation Set')\n",
        "plot_roc_curve(best_model_dt, test_features_scaled, test_labels['label'], 'Decision Tree', 'Test Set')\n",
        "\n",
        "# KNN\n",
        "plot_roc_curve(best_model_knn, X_valid_scaled, y_valid, 'KNN', 'Validation Set')\n",
        "plot_roc_curve(best_model_knn, test_features_scaled, test_labels['label'], 'KNN', 'Test Set')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81970255",
      "metadata": {},
      "source": [
        "## Save models\n",
        "\n",
        "To save scikit-learn models, we use `joblib` which is more efficient for large numpy arrays:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0075602",
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(best_model_knn, 'best_model_knn.pkl')\n",
        "joblib.dump(best_model_dt, 'best_model_dt.pkl')\n",
        "joblib.dump(dt, 'decision_tree_model.pkl')\n",
        "joblib.dump(knn, 'knn_model.pkl')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
