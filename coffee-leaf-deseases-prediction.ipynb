{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17bab194",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def rgb_to_cmy(rgb_image):\n",
        "    # CMY = 1 - RGB\n",
        "    cmy_image = 1.0 - rgb_image\n",
        "    return cmy_image\n",
        "\n",
        "def extract_color_features(image):\n",
        "    features = []\n",
        "    \n",
        "    # RGB features (6)\n",
        "    for channel in range(3):  # R, G, B\n",
        "        channel_data = image[:, :, channel]\n",
        "        features.append(np.mean(channel_data))  # Mean\n",
        "        features.append(np.std(channel_data))   # Standard deviation\n",
        "    \n",
        "    # CMY features (6)\n",
        "    cmy_image = rgb_to_cmy(image)\n",
        "    for channel in range(3):  # C, M, Y\n",
        "        channel_data = cmy_image[:, :, channel]\n",
        "        features.append(np.mean(channel_data))  # Mean\n",
        "        features.append(np.std(channel_data))   # Standard deviation\n",
        "    \n",
        "    return np.array(features)\n",
        "\n",
        "def load_and_extract_features(image_dir, labels_df):\n",
        "    features_list = []\n",
        "    valid_indices = []\n",
        "    \n",
        "    for idx, row in labels_df.iterrows():\n",
        "        img_path = os.path.join(image_dir, f\"{row['id']}.jpg\")\n",
        "        \n",
        "        if os.path.exists(img_path):\n",
        "            img = Image.open(img_path)\n",
        "            img_resized = img.resize((410, 205))\n",
        "            img_array = np.array(img_resized).astype('float32') / 255.0\n",
        "            \n",
        "            features = extract_color_features(img_array)\n",
        "            features_list.append(features)\n",
        "            valid_indices.append(idx)\n",
        "        else:\n",
        "            print(f\"Warning: {img_path} not found\")\n",
        "    \n",
        "    features_array = np.array(features_list)\n",
        "    labels = labels_df.loc[valid_indices].reset_index(drop=True)\n",
        "    \n",
        "    return features_array, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe4bc695",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "\n",
        "train_label_df = pd.read_csv('dataset/train_classes.csv')\n",
        "test_label_df = pd.read_csv('dataset/test_classes.csv')\n",
        "train_label_df['nodisease'] = 1 - (train_label_df[['miner', 'rust', 'phoma']].sum(axis=1) > 0).astype(int)\n",
        "test_label_df['nodisease'] = 1 - (test_label_df[['miner', 'rust', 'phoma']].sum(axis=1) > 0).astype(int)\n",
        "train_label_df.loc[train_label_df['miner'] == 1, 'rust'] = 0\n",
        "test_label_df.loc[test_label_df['miner'] == 1, 'rust'] = 0\n",
        "\n",
        "train_features, train_labels = load_and_extract_features('dataset/coffee-leaf-diseases/train/images', train_label_df)\n",
        "X_test, test_labels = load_and_extract_features('dataset/coffee-leaf-diseases/test/images', test_label_df)\n",
        "\n",
        "y_test = test_labels[['nodisease', 'miner', 'rust', 'phoma']]\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    train_features, \n",
        "    train_labels[['nodisease', 'miner', 'phoma', 'rust']],\n",
        "    test_size=0.2,\n",
        "    stratify=train_labels[['nodisease', 'miner', 'phoma', 'rust']],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_valid_scaled = scaler.transform(X_valid)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "17bab194",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def rgb_to_cmy(rgb_image):\n",
        "    # CMY = 1 - RGB\n",
        "    cmy_image = 1.0 - rgb_image\n",
        "    return cmy_image\n",
        "\n",
        "def extract_color_features(image):\n",
        "    features = []\n",
        "    \n",
        "    # RGB features (6)\n",
        "    for channel in range(3):  # R, G, B\n",
        "        channel_data = image[:, :, channel]\n",
        "        features.append(np.mean(channel_data))  # Mean\n",
        "        features.append(np.std(channel_data))   # Standard deviation\n",
        "    \n",
        "    # CMY features (6)\n",
        "    cmy_image = rgb_to_cmy(image)\n",
        "    for channel in range(3):  # C, M, Y\n",
        "        channel_data = cmy_image[:, :, channel]\n",
        "        features.append(np.mean(channel_data))  # Mean\n",
        "        features.append(np.std(channel_data))   # Standard deviation\n",
        "    \n",
        "    return np.array(features)\n",
        "\n",
        "def load_and_extract_features(image_dir, labels_df):\n",
        "    features_list = []\n",
        "    valid_indices = []\n",
        "    \n",
        "    for idx, row in labels_df.iterrows():\n",
        "        img_path = os.path.join(image_dir, f\"{row['id']}.jpg\")\n",
        "        \n",
        "        if os.path.exists(img_path):\n",
        "            img = Image.open(img_path)\n",
        "            img_resized = img.resize((410, 205))\n",
        "            img_array = np.array(img_resized).astype('float32') / 255.0\n",
        "            \n",
        "            features = extract_color_features(img_array)\n",
        "            features_list.append(features)\n",
        "            valid_indices.append(idx)\n",
        "        else:\n",
        "            print(f\"Warning: {img_path} not found\")\n",
        "    \n",
        "    features_array = np.array(features_list)\n",
        "    labels = labels_df.loc[valid_indices].reset_index(drop=True)\n",
        "    \n",
        "    return features_array, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fe4bc695",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "\n",
        "train_label_df = pd.read_csv('dataset/train_classes.csv')\n",
        "test_label_df = pd.read_csv('dataset/test_classes.csv')\n",
        "\n",
        "train_features, train_labels = load_and_extract_features('dataset/coffee-leaf-diseases/train/images', train_label_df)\n",
        "X_test, test_labels = load_and_extract_features('dataset/coffee-leaf-diseases/test/images', test_label_df)\n",
        "\n",
        "y_test = test_labels[['miner', 'rust', 'phoma']]\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    train_features, \n",
        "    train_labels[['miner', 'rust', 'phoma']],  # または適切なラベル列名\n",
        "    test_size=0.2,\n",
        "    stratify=train_labels[['miner', 'rust', 'phoma']],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3a3f8cd3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1011, 12)\n"
          ]
        }
      ],
      "source": [
        "print(X_train_scaled.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "807cfa4f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Evaluation Decision Tree Metrics per label ===\n",
            "miner: Accuracy=0.7200, Precision=0.5667, Recall=0.5312, F1-score=0.5484\n",
            "rust: Accuracy=0.7700, Precision=0.4074, Recall=0.6111, F1-score=0.4889\n",
            "phoma: Accuracy=0.8900, Precision=0.7097, Recall=0.9167, F1-score=0.8000\n",
            "\n",
            "=== Decision Tree Overall Metrics ===\n",
            "Accuracy (subset accuracy): 0.49\n",
            "Precision (micro): 0.5681818181818182\n",
            "Recall (micro): 0.6756756756756757\n",
            "F1-score (micro): 0.6172839506172839\n",
            "Precision (macro): 0.5612504978096376\n",
            "Recall (macro): 0.6863425925925926\n",
            "F1-score (macro): 0.6124253285543608\n",
            "\n",
            "=== Evaluation KNN Metrics per label ===\n",
            "miner: Accuracy=0.7600, Precision=0.6667, Recall=0.5000, F1-score=0.5714\n",
            "rust: Accuracy=0.8200, Precision=0.5000, Recall=0.6111, F1-score=0.5500\n",
            "phoma: Accuracy=0.9200, Precision=0.7500, Recall=1.0000, F1-score=0.8571\n",
            "\n",
            "=== KNN Overall Metrics ===\n",
            "Accuracy (subset accuracy): 0.58\n",
            "Precision (micro): 0.6538461538461539\n",
            "Recall (micro): 0.6891891891891891\n",
            "F1-score (micro): 0.6710526315789473\n",
            "Precision (macro): 0.6388888888888888\n",
            "Recall (macro): 0.7037037037037037\n",
            "F1-score (macro): 0.6595238095238095\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# ---------- Decision Tree ----------\n",
        "dt = DecisionTreeClassifier(\n",
        "    criterion='gini',\n",
        "    max_depth=None,\n",
        "    max_features=None,\n",
        "    min_samples_leaf=1,\n",
        "    min_samples_split=2,\n",
        "    random_state=123,\n",
        "    splitter='best'\n",
        ")\n",
        "multi_dt = MultiOutputClassifier(dt)\n",
        "multi_dt.fit(X_train_scaled, y_train)\n",
        "y_pred_dt = multi_dt.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"\\n=== Evaluation Decision Tree Metrics per label ===\")\n",
        "for i, label in enumerate(labels):\n",
        "    y_true = y_test[label] if hasattr(y_test, 'columns') else y_test[:, i]\n",
        "    y_pred = y_pred_dt[:, i]\n",
        "    \n",
        "    acc_dt = accuracy_score(y_true, y_pred)\n",
        "    prec_dt = precision_score(y_true, y_pred, zero_division=0)\n",
        "    rec_dt = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1_dt = f1_score(y_true, y_pred, zero_division=0)\n",
        "    \n",
        "    print(f\"{label}: Accuracy={acc_dt:.4f}, Precision={prec_dt:.4f}, Recall={rec_dt:.4f}, F1-score={f1_dt:.4f}\")\n",
        "\n",
        "print(\"\\n=== Decision Tree Overall Metrics ===\")\n",
        "print(\"Accuracy (subset accuracy):\", accuracy_score(y_test, y_pred_dt))\n",
        "print(\"Precision (micro):\", precision_score(y_test, y_pred_dt, average='micro', zero_division=0))\n",
        "print(\"Recall (micro):\", recall_score(y_test, y_pred_dt, average='micro', zero_division=0))\n",
        "print(\"F1-score (micro):\", f1_score(y_test, y_pred_dt, average='micro', zero_division=0))\n",
        "print(\"Precision (macro):\", precision_score(y_test, y_pred_dt, average='macro', zero_division=0))\n",
        "print(\"Recall (macro):\", recall_score(y_test, y_pred_dt, average='macro', zero_division=0))\n",
        "print(\"F1-score (macro):\", f1_score(y_test, y_pred_dt, average='macro', zero_division=0))\n",
        "\n",
        "# ---------- KNN ----------\n",
        "knn = KNeighborsClassifier(\n",
        "    algorithm='auto',\n",
        "    leaf_size=30,\n",
        "    metric='minkowski',\n",
        "    n_jobs=-1,\n",
        "    n_neighbors=5,\n",
        "    p=2,\n",
        "    weights='uniform'\n",
        ")\n",
        "multi_knn = MultiOutputClassifier(knn)\n",
        "multi_knn.fit(X_train_scaled, y_train)\n",
        "y_pred_knn = multi_knn.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"\\n=== Evaluation KNN Metrics per label ===\")\n",
        "for i, label in enumerate(labels):\n",
        "    y_true = y_test[label] if hasattr(y_test, 'columns') else y_test[:, i]\n",
        "    y_pred = y_pred_knn[:, i]\n",
        "    \n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "    \n",
        "    print(f\"{label}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1-score={f1:.4f}\")\n",
        "\n",
        "print(\"\\n=== KNN Overall Metrics ===\")\n",
        "print(\"Accuracy (subset accuracy):\", accuracy_score(y_test, y_pred_knn))\n",
        "print(\"Precision (micro):\", precision_score(y_test, y_pred_knn, average='micro', zero_division=0))\n",
        "print(\"Recall (micro):\", recall_score(y_test, y_pred_knn, average='micro', zero_division=0))\n",
        "print(\"F1-score (micro):\", f1_score(y_test, y_pred_knn, average='micro', zero_division=0))\n",
        "print(\"Precision (macro):\", precision_score(y_test, y_pred_knn, average='macro', zero_division=0))\n",
        "print(\"Recall (macro):\", recall_score(y_test, y_pred_knn, average='macro', zero_division=0))\n",
        "print(\"F1-score (macro):\", f1_score(y_test, y_pred_knn, average='macro', zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f5b813c",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.12/site-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
            "  _data = np.array(data, dtype=dtype, copy=copy,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'estimator__criterion': 'entropy', 'estimator__max_depth': 7, 'estimator__min_samples_leaf': 4, 'estimator__min_samples_split': 2}\n",
            "0.36944601292427376\n",
            "{'estimator__leaf_size': 25, 'estimator__metric': 'euclidean', 'estimator__n_neighbors': 8, 'estimator__p': 1, 'estimator__weights': 'uniform'}\n",
            "0.411267959094046\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.12/site-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
            "  _data = np.array(data, dtype=dtype, copy=copy,\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# ---------- Decision Tree ----------\n",
        "dt = DecisionTreeClassifier(max_features=None, random_state=123, splitter='best')\n",
        "multi_dt = MultiOutputClassifier(dt)\n",
        "param_grid_dt = {\n",
        "    'estimator__criterion': ['gini', 'entropy'],\n",
        "    'estimator__max_depth': range(1, 21),\n",
        "    'estimator__min_samples_split': range(2, 11),\n",
        "    'estimator__min_samples_leaf': range(1, 6)\n",
        "}\n",
        "grid_search_dt = GridSearchCV(multi_dt, param_grid_dt, cv=5)\n",
        "grid_search_dt.fit(X_train_features, y_train_multi)\n",
        "\n",
        "print(grid_search_dt.best_params_)\n",
        "print(grid_search_dt.best_score_)\n",
        "\n",
        "# ---------- KNN ----------\n",
        "knn = KNeighborsClassifier(algorithm='auto', n_jobs=-1)\n",
        "multi_knn = MultiOutputClassifier(knn)\n",
        "param_grid_knn = {\n",
        "    'estimator__leaf_size': range(25, 36),\n",
        "    'estimator__metric': ['euclidean', 'manhattan'],\n",
        "    'estimator__n_neighbors': range(1, 21),\n",
        "    'estimator__p': [1, 2],\n",
        "    'estimator__weights': ['uniform', 'distance'],\n",
        "}\n",
        "grid_search_knn = GridSearchCV(multi_knn, param_grid_knn, cv=5)\n",
        "grid_search_knn.fit(X_train_features, y_train_multi)\n",
        "\n",
        "print(grid_search_knn.best_params_)\n",
        "print(grid_search_knn.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c3fa861",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}